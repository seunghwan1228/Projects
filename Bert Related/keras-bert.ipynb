{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"keras-bert.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_GR1PK6jPxA1","colab_type":"code","outputId":"a9b87663-f756-4e19-afe5-ccc8b31e8864","executionInfo":{"status":"ok","timestamp":1572767508540,"user_tz":-540,"elapsed":15219,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":973}},"source":["!pip install keras-bert"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting keras-bert\n","  Downloading https://files.pythonhosted.org/packages/df/fe/bf46de1ef9d1395cd735d8df5402f5d837ef82cfd348a252ad8f32feeaef/keras-bert-0.80.0.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-bert) (1.17.3)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-bert) (2.2.5)\n","Collecting keras-transformer>=0.30.0\n","  Downloading https://files.pythonhosted.org/packages/0a/57/496b1eab888171b0801a0a44d3245a7874b8d1cc04c1fbfdbb5e3327fc7a/keras-transformer-0.31.0.tar.gz\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert) (2.8.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert) (1.12.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert) (1.3.1)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert) (1.0.8)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert) (3.13)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert) (1.1.0)\n","Collecting keras-pos-embd>=0.10.0\n","  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n","Collecting keras-multi-head>=0.22.0\n","  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n","Collecting keras-layer-normalization>=0.12.0\n","  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n","Collecting keras-position-wise-feed-forward>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n","Collecting keras-embed-sim>=0.7.0\n","  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n","Collecting keras-self-attention==0.41.0\n","  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n","Building wheels for collected packages: keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n","  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-bert: filename=keras_bert-0.80.0-cp36-none-any.whl size=37923 sha256=b6c0d1e6c2f274f13551761b1030e986515b1e600524661bc94905fb6d14bbd0\n","  Stored in directory: /root/.cache/pip/wheels/63/dc/87/3260cb91f3aa32c0f85c5375429a30c8fd988bbb48f5ee21b0\n","  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-transformer: filename=keras_transformer-0.31.0-cp36-none-any.whl size=13385 sha256=b3e9628950294a03023bb7edb0b4ff3459660b5a9590c651a6d6831605ec2cf7\n","  Stored in directory: /root/.cache/pip/wheels/a3/c5/9a/5a5130240be614a7a6fa786765d7692ae97f82601e2161bb56\n","  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7553 sha256=ed10c8ff8c6008dd9d2a55544e7040491d02082f3cd56a60941c6998be74e707\n","  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n","  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=e407aa65eeaf2ec30e425808f01770971845a9149d84250a9caf99235317bf08\n","  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n","  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=39189da587006623ff5825f9970aafab6c710ad8a749b181ff158653ab91978b\n","  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n","  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5624 sha256=24dc368c4fa77f8207a8824ac65c5cbd36c8abfc7a37338d21568ce4b1ce653e\n","  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n","  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=35b075572574befb3a395e8acc9ab138c9de92466c38aa680c5d4d6c1f843b98\n","  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17290 sha256=91ba4d1deb7a653b3a8a883ed035af9b433c2c8e2b6253827cf905a31b978336\n","  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n","Successfully built keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n","Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert\n","Successfully installed keras-bert-0.80.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.31.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bJpx5LZ9TbRa","colab_type":"code","outputId":"74dba210-129b-45aa-d46a-1b21805e7ff4","executionInfo":{"status":"ok","timestamp":1572768446978,"user_tz":-540,"elapsed":16744,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["# Run this cell to mount your Google Drive.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vf-jewNQTfZH","colab_type":"code","outputId":"98b74970-8d25-4c3b-e6f6-71d885ba8dcd","executionInfo":{"status":"ok","timestamp":1572768488277,"user_tz":-540,"elapsed":24847,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":287}},"source":["!mkdir -p ~/.kaggle\n","import json \n","token = {\"username\":\"seunghwan1228\",\"key\":\"2a8fb35ecd319bf10a02713c306059ca\"}\n","\n","with open('/content/drive/My Drive/Colab Notebooks/Kaggle Kernel/kaggle.json', 'w') as file:\n","  json.dump(token, file)\n"," \n","\n","!cp drive/'My Drive'/'Colab Notebooks'/'Kaggle Kernel'/kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!ls ~/.kaggle\n","!ls -l ~/.kaggle\n","!cat ~/.kaggle/kaggle.json\n","\n","# down load path\n","!kaggle competitions download -c jigsaw-unintended-bias-in-toxicity-classification\n","!unzip train.csv.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["kaggle.json\n","total 4\n","-rw------- 1 root root 72 Nov  3 08:07 kaggle.json\n","{\"username\": \"seunghwan1228\", \"key\": \"2a8fb35ecd319bf10a02713c306059ca\"}Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n","Downloading train.csv.zip to /content\n","100% 273M/273M [00:04<00:00, 70.2MB/s]\n","\n","Downloading test.csv.zip to /content\n"," 75% 9.00M/12.0M [00:00<00:00, 27.6MB/s]\n","100% 12.0M/12.0M [00:00<00:00, 30.3MB/s]\n","Downloading sample_submission.csv.zip to /content\n","  0% 0.00/224k [00:00<?, ?B/s]\n","100% 224k/224k [00:00<00:00, 190MB/s]\n","Archive:  train.csv.zip\n","  inflating: train.csv               \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E3VCUL3kYi2h","colab_type":"code","outputId":"0ec04374-9a21-49ae-9a3a-927e7f4ee9bc","executionInfo":{"status":"ok","timestamp":1572769782556,"user_tz":-540,"elapsed":9165,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["!wget https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-11-03 08:29:35--  https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c07::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1248381879 (1.2G) [application/zip]\n","Saving to: ‘wwm_uncased_L-24_H-1024_A-16.zip’\n","\n","wwm_uncased_L-24_H- 100%[===================>]   1.16G   175MB/s    in 7.2s    \n","\n","2019-11-03 08:29:42 (165 MB/s) - ‘wwm_uncased_L-24_H-1024_A-16.zip’ saved [1248381879/1248381879]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GO816YKDYmeN","colab_type":"code","outputId":"bc5d328d-cca2-4d28-aa9d-f9f365c8f403","executionInfo":{"status":"ok","timestamp":1572769806008,"user_tz":-540,"elapsed":15858,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["!unzip /content/wwm_uncased_L-24_H-1024_A-16.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Archive:  /content/wwm_uncased_L-24_H-1024_A-16.zip\n","   creating: wwm_uncased_L-24_H-1024_A-16/\n","  inflating: wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt.meta  \n","  inflating: wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt.data-00000-of-00001  \n","  inflating: wwm_uncased_L-24_H-1024_A-16/vocab.txt  \n","  inflating: wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt.index  \n","  inflating: wwm_uncased_L-24_H-1024_A-16/bert_config.json  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i7mSh6hKUJdx","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import sys\n","import keras\n","import tensorflow as tf\n","from keras_bert import tokenizer\n","import keras_bert\n","from tqdm import tqdm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WG6z_VpdTrpk","colab_type":"code","colab":{}},"source":["df = pd.read_csv('/content/train.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y6X-WVHpTviT","colab_type":"code","outputId":"109848ad-7703-4e93-b5c6-cf3495d2714a","executionInfo":{"status":"ok","timestamp":1572768523222,"user_tz":-540,"elapsed":9064,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":479}},"source":["df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>target</th>\n","      <th>comment_text</th>\n","      <th>severe_toxicity</th>\n","      <th>obscene</th>\n","      <th>identity_attack</th>\n","      <th>insult</th>\n","      <th>threat</th>\n","      <th>asian</th>\n","      <th>atheist</th>\n","      <th>bisexual</th>\n","      <th>black</th>\n","      <th>buddhist</th>\n","      <th>christian</th>\n","      <th>female</th>\n","      <th>heterosexual</th>\n","      <th>hindu</th>\n","      <th>homosexual_gay_or_lesbian</th>\n","      <th>intellectual_or_learning_disability</th>\n","      <th>jewish</th>\n","      <th>latino</th>\n","      <th>male</th>\n","      <th>muslim</th>\n","      <th>other_disability</th>\n","      <th>other_gender</th>\n","      <th>other_race_or_ethnicity</th>\n","      <th>other_religion</th>\n","      <th>other_sexual_orientation</th>\n","      <th>physical_disability</th>\n","      <th>psychiatric_or_mental_illness</th>\n","      <th>transgender</th>\n","      <th>white</th>\n","      <th>created_date</th>\n","      <th>publication_id</th>\n","      <th>parent_id</th>\n","      <th>article_id</th>\n","      <th>rating</th>\n","      <th>funny</th>\n","      <th>wow</th>\n","      <th>sad</th>\n","      <th>likes</th>\n","      <th>disagree</th>\n","      <th>sexual_explicit</th>\n","      <th>identity_annotator_count</th>\n","      <th>toxicity_annotator_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>59848</td>\n","      <td>0.000000</td>\n","      <td>This is so cool. It's like, 'would you want yo...</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2015-09-29 10:50:41.987077+00</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>2006</td>\n","      <td>rejected</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>59849</td>\n","      <td>0.000000</td>\n","      <td>Thank you!! This would make my life a lot less...</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2015-09-29 10:50:42.870083+00</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>2006</td>\n","      <td>rejected</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>59852</td>\n","      <td>0.000000</td>\n","      <td>This is such an urgent design problem; kudos t...</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2015-09-29 10:50:45.222647+00</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>2006</td>\n","      <td>rejected</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>59855</td>\n","      <td>0.000000</td>\n","      <td>Is this something I'll be able to install on m...</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2015-09-29 10:50:47.601894+00</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>2006</td>\n","      <td>rejected</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>59856</td>\n","      <td>0.893617</td>\n","      <td>haha you guys are a bunch of losers.</td>\n","      <td>0.021277</td>\n","      <td>0.0</td>\n","      <td>0.021277</td>\n","      <td>0.87234</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.25</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2015-09-29 10:50:48.488476+00</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>2006</td>\n","      <td>rejected</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>4</td>\n","      <td>47</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id    target  ... identity_annotator_count  toxicity_annotator_count\n","0  59848  0.000000  ...                        0                         4\n","1  59849  0.000000  ...                        0                         4\n","2  59852  0.000000  ...                        0                         4\n","3  59855  0.000000  ...                        0                         4\n","4  59856  0.893617  ...                        4                        47\n","\n","[5 rows x 45 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"5qdIH7HLTzPu","colab_type":"code","colab":{}},"source":["text_data = df['comment_text']\n","target = df['target']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y7F7yWxIT250","colab_type":"code","colab":{}},"source":["def target_binary(x):\n","  if x >= 0.5:\n","    return 1\n","  else:\n","    return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wS_G_zQIT-FC","colab_type":"code","colab":{}},"source":["target = target.apply(target_binary)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q9elnAxtT__h","colab_type":"code","outputId":"5bfc895e-42d6-45cf-bf95-a91da7dcbebf","executionInfo":{"status":"ok","timestamp":1572768600052,"user_tz":-540,"elapsed":592,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":233}},"source":["display(text_data.head())\n","display(target.head())"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":["0    This is so cool. It's like, 'would you want yo...\n","1    Thank you!! This would make my life a lot less...\n","2    This is such an urgent design problem; kudos t...\n","3    Is this something I'll be able to install on m...\n","4                 haha you guys are a bunch of losers.\n","Name: comment_text, dtype: object"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["0    0\n","1    0\n","2    0\n","3    0\n","4    1\n","Name: target, dtype: int64"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"h7lBJYr5Y9Ze","colab_type":"code","colab":{}},"source":["import keras_bert"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZWXkqCwY_A_","colab_type":"code","colab":{}},"source":["pretrained_path = '/content/wwm_uncased_L-24_H-1024_A-16'\n","\n","config_path = '/content/wwm_uncased_L-24_H-1024_A-16/bert_config.json'\n","\n","check_point_path = '/content/wwm_uncased_L-24_H-1024_A-16/bert_model.ckpt.data-00000-of-00001'\n","\n","vocab_path = '/content/wwm_uncased_L-24_H-1024_A-16/vocab.txt'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvwYnNxuZUac","colab_type":"code","colab":{}},"source":["DATA_COLUMN = 'comment_text'\n","LABEL_COLUMN = 'target'\n","\n","SEQ_LEN = 128"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NYk40QyzZZpX","colab_type":"code","colab":{}},"source":["# get tokenizer\n","\n","token_dict = keras_bert.load_vocabulary(vocab_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1tBsc5Q6ZetN","colab_type":"code","colab":{}},"source":["tokenizer = keras_bert.Tokenizer(token_dict)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ybU4z2eCZlXP","colab_type":"code","outputId":"8b757f9c-66f9-42e8-f6da-40068251bbcc","executionInfo":{"status":"ok","timestamp":1572772793795,"user_tz":-540,"elapsed":581,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tokenizer.tokenize('hello bert tokenizer &')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]', 'hello', 'bert', 'token', '##izer', '&', '[SEP]']"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"id":"oY38PtvcjS5n","colab_type":"code","outputId":"96fad7dd-4232-49cc-8a03-1b2d76f06d56","executionInfo":{"status":"ok","timestamp":1572772794613,"user_tz":-540,"elapsed":375,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tokenizer"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras_bert.tokenizer.Tokenizer at 0x7fe3f7ae9898>"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"id":"CHAl8RsMiCnz","colab_type":"code","colab":{}},"source":["def convert_data(data_df):\n","  global tokenizer\n","  indices, targets= [], []\n","  for i in tqdm(range(len(data_df))):\n","    ids, segments = tokenizer.encode(data_df[DATA_COLUMN][i], max_len=SEQ_LEN)\n","    indices.append(ids)\n","    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].apply(target_binary)\n","    targets.append(data_df[LABEL_COLUMN][i])\n","  items = list(zip(indices, targets))\n","  np.random.shuffle(items)\n","  indices, targets = zip(*items)\n","  indices = np.array(indices)\n","  return [indices, np.zeros_like(indices)], np.array(targets)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kh1b0i4AipqR","colab_type":"code","colab":{}},"source":["def load_data(path):\n","  data_df= pd.read_csv(path, nrows=10000)\n","  data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype('str')\n","  data_x, data_y = convert_data(data_df)\n","  return data_x, data_y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VOAVfGqri2y7","colab_type":"code","outputId":"1192fcfb-bdda-4275-f5c8-f29435ff6114","executionInfo":{"status":"ok","timestamp":1572773779511,"user_tz":-540,"elapsed":53367,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["train_x, train_y = load_data('/content/train.csv')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 10000/10000 [00:52<00:00, 191.26it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"OemHxCoUi7SW","colab_type":"code","outputId":"24b530c8-ab00-47eb-9c84-e2b6e5d26663","executionInfo":{"status":"ok","timestamp":1572773779512,"user_tz":-540,"elapsed":1052,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":287}},"source":["print(train_x)\n","print(len(train_x))\n","print(train_x[0].shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[array([[  101,  2056,  1996, ...,     0,     0,     0],\n","       [  101, 22889,  2819, ...,     0,     0,     0],\n","       [  101,  1996,  2373, ...,     0,     0,     0],\n","       ...,\n","       [  101,  7473,  1012, ...,  2154,  2028,   102],\n","       [  101,  1000,  1000, ...,  1012,  2096,   102],\n","       [  101,  2057,  2064, ...,     0,     0,     0]]), array([[0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0]])]\n","2\n","(10000, 128)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YXubMRXhkP7I","colab_type":"code","outputId":"804770bd-f3f0-4c10-b901-f64bfa78e142","executionInfo":{"status":"ok","timestamp":1572773779512,"user_tz":-540,"elapsed":413,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["print(train_y)\n","print(len(train_y))\n","print(train_y.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0 0 0 ... 0 0 0]\n","10000\n","(10000,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c7yvN_QvkXgP","colab_type":"text"},"source":["## load model"]},{"cell_type":"code","metadata":{"id":"_zfyy0TNkUnC","colab_type":"code","colab":{}},"source":["model = keras_bert.get_model(len(token_dict), seq_len=128)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RuNftwFjkx4F","colab_type":"code","outputId":"e952362c-d659-4d4a-f5c8-ae13f186f3ec","executionInfo":{"status":"ok","timestamp":1572773786016,"user_tz":-540,"elapsed":3824,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["bert_input = model.inputs[:2]\n","\n","print(bert_input)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[<tf.Tensor 'Input-Token_1:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Input-Segment_1:0' shape=(?, 128) dtype=float32>]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e0isz27hk5J8","colab_type":"code","colab":{}},"source":["bert_output = model.layers[-3].output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cqYHU1CmmDrc","colab_type":"code","colab":{}},"source":["real_output = keras.layers.Dense(1, activation='sigmoid')(bert_output)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TA5Q1xoamHW_","colab_type":"code","outputId":"b4d1f530-29d6-4ce5-947b-65c66c1da251","executionInfo":{"status":"ok","timestamp":1572773786375,"user_tz":-540,"elapsed":564,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["real_output"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'dense_2/Sigmoid:0' shape=(?, 1) dtype=float32>"]},"metadata":{"tags":[]},"execution_count":120}]},{"cell_type":"code","metadata":{"id":"KYouKGkvlUni","colab_type":"code","colab":{}},"source":["bert_model = keras.models.Model(bert_input, real_output)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_8lgTo60mQlA","colab_type":"code","outputId":"689cf2e6-0884-49de-e343-9d6012643285","executionInfo":{"status":"ok","timestamp":1572773788901,"user_tz":-540,"elapsed":570,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["bert_model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_4\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Input-Token (InputLayer)        (None, 128)          0                                            \n","__________________________________________________________________________________________________\n","Input-Segment (InputLayer)      (None, 128)          0                                            \n","__________________________________________________________________________________________________\n","Embedding-Token (TokenEmbedding [(None, 128, 768), ( 23440896    Input-Token[0][0]                \n","__________________________________________________________________________________________________\n","Embedding-Segment (Embedding)   (None, 128, 768)     1536        Input-Segment[0][0]              \n","__________________________________________________________________________________________________\n","Embedding-Token-Segment (Add)   (None, 128, 768)     0           Embedding-Token[0][0]            \n","                                                                 Embedding-Segment[0][0]          \n","__________________________________________________________________________________________________\n","Embedding-Position (PositionEmb (None, 128, 768)     393216      Embedding-Token-Segment[0][0]    \n","__________________________________________________________________________________________________\n","Embedding-Dropout (Dropout)     (None, 128, 768)     0           Embedding-Position[0][0]         \n","__________________________________________________________________________________________________\n","Embedding-Norm (LayerNormalizat (None, 128, 768)     1536        Embedding-Dropout[0][0]          \n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     2362368     Embedding-Norm[0][0]             \n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Embedding-Norm[0][0]             \n","                                                                 Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-1-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention-\n","                                                                 Encoder-1-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n","                                                                 Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-2-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention-\n","                                                                 Encoder-2-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n","                                                                 Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-3-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention-\n","                                                                 Encoder-3-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n","                                                                 Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-4-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention-\n","                                                                 Encoder-4-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n","                                                                 Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-5-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention-\n","                                                                 Encoder-5-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n","                                                                 Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-6-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention-\n","                                                                 Encoder-6-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n","                                                                 Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-7-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention-\n","                                                                 Encoder-7-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n","                                                                 Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-8-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention-\n","                                                                 Encoder-8-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n","                                                                 Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-9-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention-\n","                                                                 Encoder-9-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n","                                                                 Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Dropout  (None, 128, 768)     0           Encoder-10-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Add (Add (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n","                                                                 Encoder-10-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n","                                                                 Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Dropout  (None, 128, 768)     0           Encoder-11-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Add (Add (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n","                                                                 Encoder-11-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n","                                                                 Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Dropout  (None, 128, 768)     0           Encoder-12-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Add (Add (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n","                                                                 Encoder-12-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1)            769         NSP-Dense[0][0]                  \n","==================================================================================================\n","Total params: 109,483,009\n","Trainable params: 109,483,009\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g9msvtj3mVQP","colab_type":"code","colab":{}},"source":["bert_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8_rV5vomyJR","colab_type":"code","outputId":"a16c4905-2124-48fa-e144-0e119ed28aad","executionInfo":{"status":"ok","timestamp":1572773795021,"user_tz":-540,"elapsed":584,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["train_x"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([[  101,  2056,  1996, ...,     0,     0,     0],\n","        [  101, 22889,  2819, ...,     0,     0,     0],\n","        [  101,  1996,  2373, ...,     0,     0,     0],\n","        ...,\n","        [  101,  7473,  1012, ...,  2154,  2028,   102],\n","        [  101,  1000,  1000, ...,  1012,  2096,   102],\n","        [  101,  2057,  2064, ...,     0,     0,     0]]),\n"," array([[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]])]"]},"metadata":{"tags":[]},"execution_count":124}]},{"cell_type":"code","metadata":{"id":"i-RAZzzWnLoB","colab_type":"code","outputId":"b983f5ac-9cb4-4397-dfa9-354c1cdde550","executionInfo":{"status":"ok","timestamp":1572773796655,"user_tz":-540,"elapsed":585,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["train_y"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, ..., 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":125}]},{"cell_type":"code","metadata":{"id":"fGljDdm6ma_Z","colab_type":"code","outputId":"de925614-dca8-4cd7-942c-d3737742073c","executionInfo":{"status":"ok","timestamp":1572779044037,"user_tz":-540,"elapsed":5193146,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":395}},"source":["bert_model.fit(train_x, train_y, epochs=10, batch_size=32)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","10000/10000 [==============================] - 520s 52ms/step - loss: 0.2845 - acc: 0.9374\n","Epoch 2/10\n","10000/10000 [==============================] - 519s 52ms/step - loss: 0.2279 - acc: 0.9422\n","Epoch 3/10\n","10000/10000 [==============================] - 519s 52ms/step - loss: 0.2253 - acc: 0.9422\n","Epoch 4/10\n","10000/10000 [==============================] - 519s 52ms/step - loss: 0.2301 - acc: 0.9422\n","Epoch 5/10\n","10000/10000 [==============================] - 519s 52ms/step - loss: 0.2298 - acc: 0.9422\n","Epoch 6/10\n","10000/10000 [==============================] - 519s 52ms/step - loss: 0.2274 - acc: 0.9422\n","Epoch 7/10\n","10000/10000 [==============================] - 519s 52ms/step - loss: 0.2270 - acc: 0.9422\n","Epoch 8/10\n","10000/10000 [==============================] - 519s 52ms/step - loss: 0.2276 - acc: 0.9422\n","Epoch 9/10\n","10000/10000 [==============================] - 519s 52ms/step - loss: 0.2297 - acc: 0.9422\n","Epoch 10/10\n","10000/10000 [==============================] - 519s 52ms/step - loss: 0.2238 - acc: 0.9422\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe3f1801b38>"]},"metadata":{"tags":[]},"execution_count":127}]},{"cell_type":"code","metadata":{"id":"iNDOBWqJHa-W","colab_type":"code","colab":{}},"source":["def convert_test(test_df):\n","    global tokenizer\n","    indices = []\n","    for i in tqdm(range(len(test_df))):\n","        ids, segments = tokenizer.encode(test_df[DATA_COLUMN][i], max_len=SEQ_LEN)\n","        indices.append(ids)\n","    indices = np.array(indices)\n","    return [indices, np.zeros_like(indices)]\n","  \n","def load_test(data_df):\n","    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n","    data_x = convert_test(data_df)\n","    return data_x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q7qg2HQIGNXl","colab_type":"code","colab":{}},"source":["test_sentence = ['this movie is so trash']\n","\n","\n","test_sentence = pd.DataFrame({DATA_COLUMN:test_sentence})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EDZwG39AHjZA","colab_type":"code","outputId":"d440edd9-4273-4bfd-d413-1d9d85c926bf","executionInfo":{"status":"ok","timestamp":1572782287039,"user_tz":-540,"elapsed":643,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["test_x = load_test(test_sentence)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 402.02it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PFs4hEgjH8bo","colab_type":"code","outputId":"77fed231-a5ed-46f1-891a-534625fed65e","executionInfo":{"status":"ok","timestamp":1572782291656,"user_tz":-540,"elapsed":640,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":395}},"source":["test_x"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([[  101,  2023,  3185,  2003,  2061, 11669,   102,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0]]),\n"," array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]"]},"metadata":{"tags":[]},"execution_count":163}]},{"cell_type":"code","metadata":{"id":"Hy3MAmdpHAQt","colab_type":"code","outputId":"73f7098c-01d8-42b6-a5a4-288392f9da45","executionInfo":{"status":"error","timestamp":1572782234950,"user_tz":-540,"elapsed":630,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":396}},"source":["bert_model.predict(convert_test(test_sentence)[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 1231.08it/s]\n"],"name":"stderr"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-158-bb82a764a2aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             raise ValueError(\n","\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[  101,  2023,  3185,  2003,  2061, 11669,   102,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0, ..."]}]},{"cell_type":"code","metadata":{"id":"UDoC32JaG2ez","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U4mLNf0tG2c5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"72tFZnVokmBl","colab_type":"code","outputId":"f48f4df8-406d-43fc-d545-f6d59c511b89","executionInfo":{"status":"ok","timestamp":1572772945093,"user_tz":-540,"elapsed":593,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# original bert model\n","\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Input-Token (InputLayer)        (None, 128)          0                                            \n","__________________________________________________________________________________________________\n","Input-Segment (InputLayer)      (None, 128)          0                                            \n","__________________________________________________________________________________________________\n","Embedding-Token (TokenEmbedding [(None, 128, 768), ( 23440896    Input-Token[0][0]                \n","__________________________________________________________________________________________________\n","Embedding-Segment (Embedding)   (None, 128, 768)     1536        Input-Segment[0][0]              \n","__________________________________________________________________________________________________\n","Embedding-Token-Segment (Add)   (None, 128, 768)     0           Embedding-Token[0][0]            \n","                                                                 Embedding-Segment[0][0]          \n","__________________________________________________________________________________________________\n","Embedding-Position (PositionEmb (None, 128, 768)     393216      Embedding-Token-Segment[0][0]    \n","__________________________________________________________________________________________________\n","Embedding-Dropout (Dropout)     (None, 128, 768)     0           Embedding-Position[0][0]         \n","__________________________________________________________________________________________________\n","Embedding-Norm (LayerNormalizat (None, 128, 768)     1536        Embedding-Dropout[0][0]          \n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     2362368     Embedding-Norm[0][0]             \n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Embedding-Norm[0][0]             \n","                                                                 Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-1-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention-\n","                                                                 Encoder-1-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n","                                                                 Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-2-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention-\n","                                                                 Encoder-2-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n","                                                                 Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-3-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention-\n","                                                                 Encoder-3-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n","                                                                 Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-4-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention-\n","                                                                 Encoder-4-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n","                                                                 Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-5-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention-\n","                                                                 Encoder-5-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n","                                                                 Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-6-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention-\n","                                                                 Encoder-6-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n","                                                                 Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-7-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention-\n","                                                                 Encoder-7-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n","                                                                 Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-8-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention-\n","                                                                 Encoder-8-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n","                                                                 Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-9-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention-\n","                                                                 Encoder-9-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n","                                                                 Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Dropout  (None, 128, 768)     0           Encoder-10-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Add (Add (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n","                                                                 Encoder-10-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n","                                                                 Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Dropout  (None, 128, 768)     0           Encoder-11-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Add (Add (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n","                                                                 Encoder-11-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n","                                                                 Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Dropout  (None, 128, 768)     0           Encoder-12-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Add (Add (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n","                                                                 Encoder-12-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","MLM-Dense (Dense)               (None, 128, 768)     590592      Encoder-12-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","MLM-Norm (LayerNormalization)   (None, 128, 768)     1536        MLM-Dense[0][0]                  \n","__________________________________________________________________________________________________\n","Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","MLM-Sim (EmbeddingSimilarity)   (None, 128, 30522)   30522       MLM-Norm[0][0]                   \n","                                                                 Embedding-Token[0][1]            \n","__________________________________________________________________________________________________\n","Input-Masked (InputLayer)       (None, 128)          0                                            \n","__________________________________________________________________________________________________\n","NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n","__________________________________________________________________________________________________\n","MLM (Masked)                    (None, 128, 30522)   0           MLM-Sim[0][0]                    \n","                                                                 Input-Masked[0][0]               \n","__________________________________________________________________________________________________\n","NSP (Dense)                     (None, 2)            1538        NSP-Dense[0][0]                  \n","==================================================================================================\n","Total params: 110,106,428\n","Trainable params: 110,106,428\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]}]}