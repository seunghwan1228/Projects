{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq2seq without attention.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPkfKjmNrd3uCnMFkT0lSIn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"47a11044ca3e45f494c3d9f18a90f794":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0a3f15620f114e6783b1b801b16d0d9a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ee0f207176c4491e9dec4f49119e9ec6","IPY_MODEL_6dccbbe4c29d4decbbc25ab6b7bb58b7"]}},"0a3f15620f114e6783b1b801b16d0d9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee0f207176c4491e9dec4f49119e9ec6":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ce9e3eed08ec468e8612357d930fb905","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"danger","max":200,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":21,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_06f33c5e08c844e490a00e89cc4d37f1"}},"6dccbbe4c29d4decbbc25ab6b7bb58b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_182318aa19284a9e83dad99bf209f88f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10% 21/200 [1:33:59&lt;13:18:03, 267.50s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_789229d94bb0454282850f301a2a0ced"}},"ce9e3eed08ec468e8612357d930fb905":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"06f33c5e08c844e490a00e89cc4d37f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"182318aa19284a9e83dad99bf209f88f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"789229d94bb0454282850f301a2a0ced":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"73TnePQDiucs","colab_type":"code","outputId":"af732845-9d90-4260-b928-a2fff86dad80","executionInfo":{"status":"ok","timestamp":1583748837503,"user_tz":-540,"elapsed":684,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["%tensorflow_version 2.x"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-WZUrn4Ni6b4","colab_type":"code","outputId":"52be1e0b-8019-4e18-f465-8c5249706b0a","executionInfo":{"status":"ok","timestamp":1583748846023,"user_tz":-540,"elapsed":9192,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import re\n","import tensorflow as tf\n","import unicodedata\n","from tqdm import tqdm_notebook\n","print(tf.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H2_tFgpsjCCA","colab_type":"code","outputId":"986632f2-80f8-4110-ff1d-8ac1d679423b","executionInfo":{"status":"ok","timestamp":1583748848686,"user_tz":-540,"elapsed":11845,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["!wget http://www.manythings.org/anki/fra-eng.zip\n","!unzip fra-eng.zip"],"execution_count":4,"outputs":[{"output_type":"stream","text":["--2020-03-09 10:13:11--  http://www.manythings.org/anki/fra-eng.zip\n","Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:3033::6818:6dc4, ...\n","Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5939832 (5.7M) [application/zip]\n","Saving to: ‘fra-eng.zip’\n","\n","\rfra-eng.zip           0%[                    ]       0  --.-KB/s               \rfra-eng.zip          30%[=====>              ]   1.71M  8.28MB/s               \rfra-eng.zip         100%[===================>]   5.66M  21.1MB/s    in 0.3s    \n","\n","2020-03-09 10:13:12 (21.1 MB/s) - ‘fra-eng.zip’ saved [5939832/5939832]\n","\n","Archive:  fra-eng.zip\n","  inflating: _about.txt              \n","  inflating: fra.txt                 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ex4ogxCvjOHr","colab_type":"code","colab":{}},"source":["df = pd.read_csv('/content/fra.txt', sep='\\t', header=None)\n","df.columns = ['eng', 'fra', 'attr']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hpL29bG5jWrt","colab_type":"code","outputId":"a44f1d3a-22db-444c-bd72-ccb744e0e9c3","executionInfo":{"status":"ok","timestamp":1583748849278,"user_tz":-540,"elapsed":12425,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>fra</th>\n","      <th>attr</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hi.</td>\n","      <td>Salut.</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Cours !</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Run!</td>\n","      <td>Courez !</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    eng       fra                                               attr\n","0   Go.      Va !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n","1   Hi.   Salut !  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n","2   Hi.    Salut.  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n","3  Run!   Cours !  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n","4  Run!  Courez !  CC-BY 2.0 (France) Attribution: tatoeba.org #9..."]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"PBqBkNxxjbO0","colab_type":"code","colab":{}},"source":["df = df[['eng', 'fra']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MzxnnfB-jc7a","colab_type":"code","outputId":"8d702925-7286-4e8b-8d82-d4c9e8f2e094","executionInfo":{"status":"ok","timestamp":1583748849279,"user_tz":-540,"elapsed":12414,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df.head()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>fra</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hi.</td>\n","      <td>Salut.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Cours !</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Run!</td>\n","      <td>Courez !</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    eng       fra\n","0   Go.      Va !\n","1   Hi.   Salut !\n","2   Hi.    Salut.\n","3  Run!   Cours !\n","4  Run!  Courez !"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"WBx1GcnmjehS","colab_type":"text"},"source":["### Clear text"]},{"cell_type":"code","metadata":{"id":"uTjLA3uejfPP","colab_type":"code","colab":{}},"source":["def unicode_to_ascii(sentence):\n","  return ''.join(char for char in unicodedata.normalize('NFD', sentence) if unicodedata.category(char) != 'Mn')\n","\n","def clean_text(sentence):\n","  s = unicode_to_ascii(sentence.lower().strip())\n","  s = re.sub(r'([!.,?])', r' \\1 ', s)\n","  s = re.sub(r'[^a-zA-Z!.,?]+', r' ', s)\n","  s = re.sub(r'[\\s]+', ' ', s)\n","  s = '<start> ' + s + ' <end>'\n","  return s"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxDpsJfjj_Yy","colab_type":"code","outputId":"e3b18913-5970-45a7-c1a2-c6a76b3d3c7a","executionInfo":{"status":"ok","timestamp":1583748849279,"user_tz":-540,"elapsed":12402,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["test_sentence = 'helllo!  its   me.'\n","\n","print(clean_text(test_sentence))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["<start> helllo ! its me .  <end>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SxHLZLXBko8v","colab_type":"code","colab":{}},"source":["df['eng_clean'] = df['eng'].apply(clean_text)\n","df['fra_clean'] = df['fra'].apply(clean_text)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7foBugikvdZ","colab_type":"code","outputId":"0946eaf3-9f18-4e56-b96b-89cfe91a3244","executionInfo":{"status":"ok","timestamp":1583748854743,"user_tz":-540,"elapsed":17854,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df.head()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eng</th>\n","      <th>fra</th>\n","      <th>eng_clean</th>\n","      <th>fra_clean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","      <td>&lt;start&gt; go .  &lt;end&gt;</td>\n","      <td>&lt;start&gt; va !  &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","      <td>&lt;start&gt; hi .  &lt;end&gt;</td>\n","      <td>&lt;start&gt; salut !  &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hi.</td>\n","      <td>Salut.</td>\n","      <td>&lt;start&gt; hi .  &lt;end&gt;</td>\n","      <td>&lt;start&gt; salut .  &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Cours !</td>\n","      <td>&lt;start&gt; run !  &lt;end&gt;</td>\n","      <td>&lt;start&gt; cours !  &lt;end&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Run!</td>\n","      <td>Courez !</td>\n","      <td>&lt;start&gt; run !  &lt;end&gt;</td>\n","      <td>&lt;start&gt; courez !  &lt;end&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    eng       fra             eng_clean                fra_clean\n","0   Go.      Va !   <start> go .  <end>      <start> va !  <end>\n","1   Hi.   Salut !   <start> hi .  <end>   <start> salut !  <end>\n","2   Hi.    Salut.   <start> hi .  <end>   <start> salut .  <end>\n","3  Run!   Cours !  <start> run !  <end>   <start> cours !  <end>\n","4  Run!  Courez !  <start> run !  <end>  <start> courez !  <end>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"Nq3NzAHjkwe3","colab_type":"code","colab":{}},"source":["eng_data = df['eng_clean'].tolist()\n","fra_data = df['fra_clean'].tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WK6pvIgVk1OA","colab_type":"code","colab":{}},"source":["def lang_tokenize(data):\n","  lang_token = tf.keras.preprocessing.text.Tokenizer(filters='')\n","  lang_token.fit_on_texts(data)\n","\n","  convert_data = lang_token.texts_to_sequences(data)\n","  return convert_data, lang_token"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K_T9xl4BlLja","colab_type":"code","colab":{}},"source":["eng_token_data, eng_token = lang_tokenize(eng_data)\n","fra_token_data, fra_token = lang_tokenize(fra_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YqfOtlvFm8Uf","colab_type":"code","outputId":"366ad1de-a3e0-41cf-e37a-fdc17ba9cdd2","executionInfo":{"status":"ok","timestamp":1583748860031,"user_tz":-540,"elapsed":23125,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# Get # of vocabulary\n","\n","eng_vocab_size = len(eng_token.word_index) + 1\n","fra_vocab_size = len(fra_token.word_index) + 1\n","\n","print(eng_vocab_size)\n","print(fra_vocab_size)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["13860\n","22791\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fr0DxqS1lPQe","colab_type":"code","colab":{}},"source":["def max_seq_length(data):\n","  return max([len(seq) for seq in data])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0GK55OJPlnQ2","colab_type":"code","outputId":"eafbf79f-1415-4192-d131-85af8fbb5916","executionInfo":{"status":"ok","timestamp":1583748860316,"user_tz":-540,"elapsed":23399,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["eng_maxlen = max_seq_length(eng_token_data)\n","fra_maxlen = max_seq_length(fra_token_data)\n","\n","\n","print(eng_maxlen)\n","print(fra_maxlen)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["54\n","65\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fgsl-aatluGh","colab_type":"code","colab":{}},"source":["def padding_data(data):\n","  maxlen = max_seq_length(data)\n","  return tf.keras.preprocessing.sequence.pad_sequences(data, maxlen=maxlen, padding='post')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C6JT5E31l8ZZ","colab_type":"code","colab":{}},"source":["eng_token_data = padding_data(eng_token_data)\n","fra_token_data = padding_data(fra_token_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S8h7T3Z6mD9z","colab_type":"code","outputId":"a077544e-9a22-40c4-d2be-fc2ba0723738","executionInfo":{"status":"ok","timestamp":1583748861622,"user_tz":-540,"elapsed":24689,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["eng_token_data"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   1,   49,    3, ...,    0,    0,    0],\n","       [   1, 2658,    3, ...,    0,    0,    0],\n","       [   1, 2658,    3, ...,    0,    0,    0],\n","       ...,\n","       [   1,  365,   51, ...,    0,    0,    0],\n","       [   1,   69,  280, ...,    3,    2,    0],\n","       [   1,   14,  175, ..., 3418,    3,    2]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"0U70_kIomGBt","colab_type":"code","outputId":"da19a78b-df79-4090-c6d0-33c1a9333926","executionInfo":{"status":"ok","timestamp":1583748861622,"user_tz":-540,"elapsed":24680,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["fra_token_data"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   1,  123,   38, ...,    0,    0,    0],\n","       [   1, 3538,   38, ...,    0,    0,    0],\n","       [   1, 3538,    3, ...,    0,    0,    0],\n","       ...,\n","       [   1, 7296,   12, ...,    0,    0,    0],\n","       [   1,   60,  175, ..., 2108,    3,    2],\n","       [   1,   12,    9, ...,    2,    0,    0]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"TE8jPLafmHMo","colab_type":"code","colab":{}},"source":["eng_input = eng_token_data\n","fra_input = fra_token_data\n","fra_output = np.zeros(shape=fra_input.shape, dtype=np.int)\n","fra_output[:, :-1] = fra_input[:, 1:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"scBAtamAmT_K","colab_type":"code","outputId":"a533c648-94d2-49b5-a63a-891ac31f5254","executionInfo":{"status":"ok","timestamp":1583748861623,"user_tz":-540,"elapsed":24670,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":485}},"source":["print(eng_input.shape)\n","print(eng_input)\n","print('==========')\n","print(fra_input.shape)\n","print(fra_input)\n","print('==========')\n","print(fra_output.shape)\n","print(fra_output)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["(174481, 54)\n","[[   1   49    3 ...    0    0    0]\n"," [   1 2658    3 ...    0    0    0]\n"," [   1 2658    3 ...    0    0    0]\n"," ...\n"," [   1  365   51 ...    0    0    0]\n"," [   1   69  280 ...    3    2    0]\n"," [   1   14  175 ... 3418    3    2]]\n","==========\n","(174481, 65)\n","[[   1  123   38 ...    0    0    0]\n"," [   1 3538   38 ...    0    0    0]\n"," [   1 3538    3 ...    0    0    0]\n"," ...\n"," [   1 7296   12 ...    0    0    0]\n"," [   1   60  175 ... 2108    3    2]\n"," [   1   12    9 ...    2    0    0]]\n","==========\n","(174481, 65)\n","[[ 123   38    2 ...    0    0    0]\n"," [3538   38    2 ...    0    0    0]\n"," [3538    3    2 ...    0    0    0]\n"," ...\n"," [7296   12   42 ...    0    0    0]\n"," [  60  175   21 ...    3    2    0]\n"," [  12    9  105 ...    0    0    0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aNkVUThpmtJy","colab_type":"code","outputId":"4db1f1ef-566f-4724-8959-f78da7baa092","executionInfo":{"status":"ok","timestamp":1583748861624,"user_tz":-540,"elapsed":24661,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["print(fra_input.shape)\n","print(fra_input[0])\n","print('==========')\n","print(fra_output.shape)\n","print(fra_output[0])"],"execution_count":25,"outputs":[{"output_type":"stream","text":["(174481, 65)\n","[  1 123  38   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0]\n","==========\n","(174481, 65)\n","[123  38   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QGm6_2Jemwze","colab_type":"text"},"source":["## Build Encoder Decoder Architecture"]},{"cell_type":"code","metadata":{"id":"pcyOffgpmwrA","colab_type":"code","colab":{}},"source":["class Encoder(tf.keras.Model):\n","  def __init__(self, vocab_size, emb_dim, rnn_units):\n","    super(Encoder, self).__init__()\n","    self.vocab_size = vocab_size\n","    self.emb_dim = emb_dim\n","    self.rnn_units = rnn_units\n","\n","    self.emb = tf.keras.layers.Embedding(vocab_size, emb_dim)\n","    self.gru_1 = tf.compat.v1.keras.layers.CuDNNGRU(rnn_units, return_sequences=True, return_state=True, name='encoder')\n","\n","  def call(self, x, hidden):\n","    emb = self.emb(x)\n","    rnn_out, rnn_hidden = self.gru_1(emb, initial_state=hidden)\n","    return rnn_out, rnn_hidden\n","\n","  def initial_hidden(self, batch_size):\n","    return tf.zeros([batch_size, self.rnn_units])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zBeHnxKUoZR0","colab_type":"code","colab":{}},"source":["# debuging\n","test_input = tf.constant([1,2,3,4,5,6,7,8,9,0])\n","test_input = tf.expand_dims(test_input, 0)\n","\n","test_enc = Encoder(100, 120, 200) # vocab-size, emb-dim, rnn-units\n","\n","rnn_initial_hidden = test_enc.initial_hidden(1)\n","rnn_out, hidden = test_enc(test_input, rnn_initial_hidden)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DoZDpr-Pplid","colab_type":"code","outputId":"2d06b3a4-e2e0-453b-bd12-ce7f736c5e7c","executionInfo":{"status":"ok","timestamp":1583748874657,"user_tz":-540,"elapsed":37677,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["print('rnn output shape')\n","print(rnn_out.shape, '\\n')\n","print('output hidden state')\n","print(hidden.shape)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["rnn output shape\n","(1, 10, 200) \n","\n","output hidden state\n","(1, 200)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pjbA3ONcpt9E","colab_type":"code","colab":{}},"source":["class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, emb_dim, rnn_units):\n","    super(Decoder,self).__init__()\n","    self.vocab_size = vocab_size\n","    self.emb_dim =emb_dim\n","    self.rnn_units=rnn_units\n","\n","    self.emb = tf.keras.layers.Embedding(vocab_size, emb_dim)\n","    self.gru_1 = tf.compat.v1.keras.layers.CuDNNGRU(rnn_units, return_sequences=True, return_state=True, name='decoder')\n","    # self.out_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')\n","    self.out_layer = tf.keras.layers.Dense(vocab_size)\n","\n","\n","  def call(self, x, hidden):\n","    emb = self.emb(x)\n","    rnn_out, rnn_hidden = self.gru_1(emb, initial_state=hidden)\n","    result = self.out_layer(rnn_out)\n","\n","    return result, rnn_hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FTcq2sPTovc-","colab_type":"code","colab":{}},"source":["# debuging\n","test_input = tf.constant([1,2,3,4,5,6,7,8,9,0])\n","test_input = tf.expand_dims(test_input, 0)\n","\n","\n","test_dec = Decoder(100, 120, 200) # vocab-size, emb-dim, rnn-units\n","\n","\n","decoder_initial_hidden = hidden # from encoder hidden_state\n","rnn_out, hidden = test_dec(test_input, decoder_initial_hidden)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aF-JaXGtrAnY","colab_type":"code","outputId":"814f4a13-c85a-4331-f3a5-ce25e15441ee","executionInfo":{"status":"ok","timestamp":1583748876147,"user_tz":-540,"elapsed":39153,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["print('rnn output shape')\n","print(rnn_out.shape, '\\n')\n","print('output hidden state')\n","print(hidden.shape)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["rnn output shape\n","(1, 10, 100) \n","\n","output hidden state\n","(1, 200)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qE-D1EjNrLsE","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 128\n","\n","dataset = tf.data.Dataset.from_tensor_slices((eng_input, fra_input, fra_output))\n","dataset = dataset.batch(BATCH_SIZE)\n","\n","encoder = Encoder(eng_vocab_size, 256, 512)\n","decoder = Decoder(fra_vocab_size, 256, 512)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DUdhtZvcrsJv","colab_type":"code","colab":{}},"source":["LOSS_OBJECT = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","def loss_func(true, pred):\n","  mask = tf.math.logical_not(tf.math.equal(true, 0))\n","  mask = tf.cast(mask, dtype=tf.int64)\n","\n","  loss = LOSS_OBJECT(true, pred, sample_weight=mask)\n","  return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KwtUCjeRtoXj","colab_type":"code","colab":{}},"source":["optimizer = tf.keras.optimizers.Adam(clipnorm=5.0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"koQDqFwesM6e","colab_type":"code","colab":{}},"source":["@tf.function\n","def train_step(eng_input, fra_input, fra_output, en_init_state):\n","\n","  # total_loss = 0\n","  with tf.GradientTape() as tape:\n","    enc_output, enc_hidden = encoder(eng_input, en_init_state)\n","\n","    dec_hidden = enc_hidden\n","\n","    de_outputs = decoder(fra_input, dec_hidden)\n","    logits= de_outputs[0]\n","    loss = loss_func(fra_output, logits)\n","\n","  train_vars = encoder.trainable_variables + decoder.trainable_variables\n","  grad = tape.gradient(loss, train_vars)\n","  optimizer.apply_gradients(zip(grad, train_vars))\n","\n","  return loss "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qNce7CU75Ql_","colab_type":"code","outputId":"30b5e133-fb9d-43fa-9b40-8440fb986fd3","executionInfo":{"status":"ok","timestamp":1583748905630,"user_tz":-540,"elapsed":633,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["steps_per_epoch = len(eng_input) // BATCH_SIZE\n","\n","steps_per_epoch"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1363"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"9eJcyw8XyNLE","colab_type":"code","colab":{}},"source":["def inference():\n","  fra_idx_word = {v: k for k, v in fra_token.word_index.items()}\n","\n","  selection_index = np.random.choice(len(eng_data))\n","  sample_eng_sequence = eng_data[selection_index]\n","  sample_fra_sequence = fra_data[selection_index]\n","  print('Original Eng Sentence - Preprocessed')\n","  print(sample_eng_sequence)\n","  print('=======================')\n","  print('Original Fra Sentence -Preprocessed')\n","  print(sample_fra_sequence)\n","\n","  \n","  eng_inference_data = eng_token.texts_to_sequences([sample_eng_sequence])\n","  eng_inference_data = tf.keras.preprocessing.sequence.pad_sequences(eng_inference_data, maxlen=eng_maxlen, padding='post')\n","\n","  eng_inference_data = tf.constant(eng_inference_data)\n","  en_init_state = encoder.initial_hidden(1)\n","  encoder_output, encoder_hidden = encoder(eng_inference_data, en_init_state)\n","\n","  de_input = tf.constant([[fra_token.word_index['<start>']]]) # (1,1)\n","  de_init_state = encoder_hidden\n","\n","  out_word = []\n","  while True:\n","    de_output, de_init_state = decoder(de_input, de_init_state)\n","    # print(de_output, de_init_state)\n","    # print(tf.argmax(de_output, -1))\n","    de_input = tf.argmax(de_output, -1)\n","    \n","    # print(de_input.numpy()[0][0])\n","    out_word.append(fra_idx_word[de_input.numpy()[0][0]])\n","\n","    if out_word[-1] == '<end>' or len(out_word) >= 20:\n","      break\n","  \n","  print('----------------------')\n","  print('Translated Result')\n","  print(' '.join(out_word))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dIshOnUx0jPr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":161},"outputId":"f198d3e3-8670-433e-c177-62b6660eea12","executionInfo":{"status":"ok","timestamp":1583749827716,"user_tz":-540,"elapsed":601,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["inference()"],"execution_count":80,"outputs":[{"output_type":"stream","text":["Original Eng Sentence - Preprocessed\n","<start> he has enough ability to manage a business .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> il est assez apte a gerer une affaire .  <end>\n","----------------------\n","Translated Result\n","parlerait reincarne figurine ustensiles sejournez rirais debats deregule empoisonnez repondez realisent distribue abstrait changent monroe curiosite deconseilla maladroit affreuses insolence\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vc-3yI3Btw2A","colab_type":"code","outputId":"7b971484-f9a3-49da-db47-6c2174113ace","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["47a11044ca3e45f494c3d9f18a90f794","0a3f15620f114e6783b1b801b16d0d9a","ee0f207176c4491e9dec4f49119e9ec6","6dccbbe4c29d4decbbc25ab6b7bb58b7","ce9e3eed08ec468e8612357d930fb905","06f33c5e08c844e490a00e89cc4d37f1","182318aa19284a9e83dad99bf209f88f","789229d94bb0454282850f301a2a0ced"]},"executionInfo":{"status":"error","timestamp":1583755710560,"user_tz":-540,"elapsed":5874941,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["EPOCH = 200\n","\n","for epoch in tqdm_notebook(range(EPOCH)):\n","  enc_hidden = encoder.initial_hidden(BATCH_SIZE)\n","  \n","  for n, (eng, fra, fra_targ) in enumerate(dataset.take(steps_per_epoch)):\n","    batch_loss = train_step(eng, fra, fra_targ, enc_hidden)\n","\n","    if n % 100 == 0:\n","      print('batch loss:', batch_loss)\n","\n","  print(epoch, '\\t', batch_loss,'\\n')\n","  print('------- INFERENCE MODE --------')\n","  print(inference())"],"execution_count":81,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47a11044ca3e45f494c3d9f18a90f794","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["batch loss: tf.Tensor(0.6259085, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.4528869, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.47813782, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.6457364, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.6598836, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.5036615, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.64032376, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.5848668, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.5931212, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.6816991, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.6987297, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.7667793, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.7937891, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.8782541, shape=(), dtype=float32)\n","0 \t tf.Tensor(2.1257715, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> do you like me , too ?  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> m appreciez vous aussi ?  <end>\n","----------------------\n","Translated Result\n","je ne peux pas pas que tu ne peux pas pas que je ne peux pas pas a la reunion\n","None\n","batch loss: tf.Tensor(0.45525795, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.29516637, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.3031903, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.40285406, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.41147995, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.35894826, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.42820346, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.39476398, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.41772854, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.48635942, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.5303607, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.5970719, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.6025686, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.6924215, shape=(), dtype=float32)\n","1 \t tf.Tensor(1.8239293, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> it s too large .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> c est trop grand .  <end>\n","----------------------\n","Translated Result\n","il est improbable que je n ai jamais pu etre en mesure de parler a la reunion de la reunion\n","None\n","batch loss: tf.Tensor(0.3797463, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.22555533, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.23519818, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.28046224, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.30918095, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.2848478, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.33754432, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.32058024, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.33698776, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.38940704, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.4412221, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.4641444, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.49855334, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.57644385, shape=(), dtype=float32)\n","2 \t tf.Tensor(1.5818559, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> he was a bit embarrassed .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> il etait un peu dans l embarras .  <end>\n","----------------------\n","Translated Result\n","il a ete blesse a l universite de l universite , mais il a ete en mesure de l universite\n","None\n","batch loss: tf.Tensor(0.30652165, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.1692664, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.185648, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.23257346, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.25578374, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.22248474, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.2699878, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.24130428, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.24889125, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.32085863, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.355158, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.3701758, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.40754738, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.46990868, shape=(), dtype=float32)\n","3 \t tf.Tensor(1.3841294, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> don t use your real name .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> n utilise pas ton vrai nom .  <end>\n","----------------------\n","Translated Result\n","ne choisissez pas votre temps a penser aux choses que je doive faire . <end>\n","None\n","batch loss: tf.Tensor(0.22206208, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.14009412, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.14675842, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.18120024, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.21415086, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.1774204, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.21773997, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.18223466, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.18951455, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.26346222, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.28724524, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.2955366, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.3260025, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.38201553, shape=(), dtype=float32)\n","4 \t tf.Tensor(1.2057382, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> nobody cares for me .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> personne ne s occupe de moi .  <end>\n","----------------------\n","Translated Result\n","personne ne m a autorise a m empecher de rire de mon comportement de la possibilite que je ne l\n","None\n","batch loss: tf.Tensor(0.1713773, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.11161978, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.11353697, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.1454849, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.16544326, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.14083706, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.17840625, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.13920745, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.1463525, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.22272186, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.23424706, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.22916675, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.2681071, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.31207734, shape=(), dtype=float32)\n","5 \t tf.Tensor(1.0557047, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> he was very happy .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> il fut tres heureux .  <end>\n","----------------------\n","Translated Result\n","il etait tres heureux d etre satisfait des resultats et les autres et l ete et bien . <end>\n","None\n","batch loss: tf.Tensor(0.14051129, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.08769118, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.09185661, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.124374196, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.13371274, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.11245597, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.15241756, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.116385125, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.120597154, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.18590635, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.19495967, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.18220468, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.22780932, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.25539654, shape=(), dtype=float32)\n","6 \t tf.Tensor(0.925901, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> that s simple .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> c est simple .  <end>\n","----------------------\n","Translated Result\n","c est simple regle . <end>\n","None\n","batch loss: tf.Tensor(0.11758839, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.06837578, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.076588586, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.10851596, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.122000866, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.09199203, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.131004, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.09208921, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.101468496, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.16341543, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.16419816, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.15216321, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.1922219, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.21556987, shape=(), dtype=float32)\n","7 \t tf.Tensor(0.821487, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> freedom is so fundamental that its importance cannot be overemphasized .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> la liberte est si importante que nous n insisterons jamais assez sur son importance .  <end>\n","----------------------\n","Translated Result\n","la liberte est si importante que nous n insisterons pas encore vendu les memes . <end>\n","None\n","batch loss: tf.Tensor(0.102477, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.060329724, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.063941166, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.09597466, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.09824775, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.0764266, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.11393821, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.081472166, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.08360729, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.13689508, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.13999613, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.12480551, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.16014947, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.18202826, shape=(), dtype=float32)\n","8 \t tf.Tensor(0.7516826, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> none of us are opposed to his ideas .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> aucun d entre nous n est oppose a ses idees .  <end>\n","----------------------\n","Translated Result\n","aucun des ses camarades de classe ne s est pas excuse . <end>\n","None\n","batch loss: tf.Tensor(0.09783061, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.04852061, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.05663872, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.09287068, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.08661474, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.06780173, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.1018745, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.07069491, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.072335936, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.11840575, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.11636528, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.10424098, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.13878159, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.16150679, shape=(), dtype=float32)\n","9 \t tf.Tensor(0.71106344, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> i have almost no money now .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> je n ai presque plus d argent , maintenant .  <end>\n","----------------------\n","Translated Result\n","je n ai toujours pas d argent a cause de l argent maintenant , peu d argent a divers organismes\n","None\n","batch loss: tf.Tensor(0.08717632, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.047405656, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.052237388, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.08889607, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.08910103, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.058946118, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.09550075, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.06779877, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.06652726, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.10747443, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.10106229, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.09071076, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.12014604, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.14921607, shape=(), dtype=float32)\n","10 \t tf.Tensor(0.6168542, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> tom plays tennis after school three days a week .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> tom joue au tennis apres l ecole trois fois par semaine .  <end>\n","----------------------\n","Translated Result\n","tom joue au tennis apres trois fois par semaine au moins trois fois par semaine . <end>\n","None\n","batch loss: tf.Tensor(0.080752894, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.042473152, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.047656666, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.0784477, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.081951715, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.056243744, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.08579251, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.061734553, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.061568458, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.09415038, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.09216103, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.0818067, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.106575385, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.120892234, shape=(), dtype=float32)\n","11 \t tf.Tensor(0.5710015, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> i didn t even bring a jacket .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> je n ai meme pas apporte de veste .  <end>\n","----------------------\n","Translated Result\n","je n ai meme pas veste d avoir une veste de cigarette . <end>\n","None\n","batch loss: tf.Tensor(0.08006544, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.037644092, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.042391755, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.074302316, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.07139228, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.047982164, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.07649463, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.056510214, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.05470954, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.08820637, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.08297706, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.070483305, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.098413646, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.11000444, shape=(), dtype=float32)\n","12 \t tf.Tensor(0.51438075, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> she writes beautifully .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> elle ecrit magnifiquement .  <end>\n","----------------------\n","Translated Result\n","elle ecrit des scenarios . <end>\n","None\n","batch loss: tf.Tensor(0.080550015, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.037679084, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.04281096, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.061714914, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.06773769, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.045584492, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.07380191, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.050100885, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.04856895, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.07674164, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.07840509, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.06738381, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.09569103, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.09824907, shape=(), dtype=float32)\n","13 \t tf.Tensor(0.46692556, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> i want something sweet .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> je veux quelque chose de sucre .  <end>\n","----------------------\n","Translated Result\n","je veux quelque chose de sucre , alors merci . c est en train de devenir debutant . <end>\n","None\n","batch loss: tf.Tensor(0.071806096, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.034595735, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.037189938, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.060018122, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.06297134, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.042077225, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.0650189, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.04812012, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.046492487, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.07104035, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.06394087, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.059246488, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.07817515, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.09216829, shape=(), dtype=float32)\n","14 \t tf.Tensor(0.41669405, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> i remember my mother teaching me the alphabet .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> je me souviens de ma mere m enseignant l alphabet .  <end>\n","----------------------\n","Translated Result\n","je me souviens de ma mere me rappelle l ami dont l accident a ete tres agreable . <end>\n","None\n","batch loss: tf.Tensor(0.071212575, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.030642193, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.034597993, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.056382366, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.055527057, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.038558867, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.060383588, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.047575746, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.043120686, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.06424274, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.063192844, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.051336568, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.07817674, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.08697137, shape=(), dtype=float32)\n","15 \t tf.Tensor(0.3698947, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> i suppose you re hungry .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> j imagine que tu as faim .  <end>\n","----------------------\n","Translated Result\n","je suppose que vous avez faim . sans raison de faim et mal a perdre . <end>\n","None\n","batch loss: tf.Tensor(0.06831561, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.031965386, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.032448087, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.055385407, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.051272348, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.036198962, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.056132205, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.047148902, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.042717025, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.061062556, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.054550987, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.048030023, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.073087454, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.079889916, shape=(), dtype=float32)\n","16 \t tf.Tensor(0.3768502, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> i never meant to hurt any of you .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> je n avais pas l intention de blesser qui que ce soit parmi vous .  <end>\n","----------------------\n","Translated Result\n","je n avais jamais ete blesse a part de faire quoi que ce que vous blesser , j ai oublie\n","None\n","batch loss: tf.Tensor(0.05814732, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.031962745, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.03357145, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.048870012, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.061762415, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.033652518, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.055747632, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.0438061, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.040475126, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.057940174, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.05011974, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.047642343, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.06926306, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.074883625, shape=(), dtype=float32)\n","17 \t tf.Tensor(0.33548695, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> be more careful from now on .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> soyez desormais plus prudents .  <end>\n","----------------------\n","Translated Result\n","soyez desormais plus prudent a traiter les phrases de l autre maintenant . <end>\n","None\n","batch loss: tf.Tensor(0.06008569, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.03239941, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.03466651, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.05381098, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.05523164, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.0334362, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.05126952, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.041167025, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.03877159, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.053807966, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.047583375, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.041312758, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.067015365, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.07183751, shape=(), dtype=float32)\n","18 \t tf.Tensor(0.29164937, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> count up to thirty .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> comptez jusqu a trente .  <end>\n","----------------------\n","Translated Result\n","compte trente a trente secondes . <end>\n","None\n","batch loss: tf.Tensor(0.057980027, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.030568521, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.030852363, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.048987463, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.05031276, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.03252821, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.049859066, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.04208429, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.035849433, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.05143349, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.04347954, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.04259277, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.063375324, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.07033109, shape=(), dtype=float32)\n","19 \t tf.Tensor(0.30038336, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> my father won t allow me to do that .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> mon pere ne m autorisera pas a faire cela .  <end>\n","----------------------\n","Translated Result\n","mon pere ne m autorisera a faire ca . <end>\n","None\n","batch loss: tf.Tensor(0.053838927, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.027031288, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.02934207, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.0456933, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.044157483, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.03364117, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.05099128, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.042320605, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.040910754, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.04833924, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.04397274, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.04222496, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.05424194, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.06008022, shape=(), dtype=float32)\n","20 \t tf.Tensor(0.3029412, shape=(), dtype=float32) \n","\n","------- INFERENCE MODE --------\n","Original Eng Sentence - Preprocessed\n","<start> she was satisfied with the new dress .  <end>\n","=======================\n","Original Fra Sentence -Preprocessed\n","<start> la nouvelle robe lui plut .  <end>\n","----------------------\n","Translated Result\n","elle fut contente de la nouvelle robe que la robe de la majorite des hommes . <end>\n","None\n","batch loss: tf.Tensor(0.050448433, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.02854102, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.027340835, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.0428184, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.04821019, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.027816635, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.046277493, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.04303042, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.033349827, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.045108665, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.03905738, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.038150918, shape=(), dtype=float32)\n","batch loss: tf.Tensor(0.05337145, shape=(), dtype=float32)\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-81-7ce3e8e07404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfra_targ\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfra_targ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}