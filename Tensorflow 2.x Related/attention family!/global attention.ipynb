{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"global attention.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMKiSsenJJhHNUTmn5jH+3E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Ed1UWxRcqpF3","colab_type":"text"},"source":["https://github.com/uzaymacar/attention-mechanisms/blob/master/layers.py"]},{"cell_type":"code","metadata":{"id":"Wtr22kM4aS97","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"fe2b8d3d-b6dd-4ded-dce3-12ca175d4b97","executionInfo":{"status":"ok","timestamp":1583239247829,"user_tz":-540,"elapsed":1348,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["%tensorflow_version 2.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"60aRHLmSaY4Z","colab_type":"code","colab":{}},"source":["import argparse\n","import time\n","import os\n","import unicodedata\n","import re\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.utils import get_file, to_categorical\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Input, Embedding, Bidirectional, Dense, RepeatVector, TimeDistributed, Flatten, Lambda, Concatenate, Permute, Reshape\n","from tensorflow.compat.v1.keras.layers import CuDNNLSTM   # CuDNNLSTM not yet released for TF 2.0\n","from tensorflow.keras.backend import permute_dimensions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5flmjoNabfqU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"f5e2d0b0-f9d8-4530-d6cb-705300435324","executionInfo":{"status":"ok","timestamp":1583239699226,"user_tz":-540,"elapsed":827,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["# Argument specification\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\"--config\",\n","                    default=0,\n","                    help=\"Integer value representing a model configuration\")"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["_StoreAction(option_strings=['--config'], dest='config', nargs=None, const=None, default=0, type=None, choices=None, help='Integer value representing a model configuration', metavar=None)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"pbdEk2Jxb-Fn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":190},"outputId":"26ee2e45-72df-45fd-d16f-8a58c73607d1","executionInfo":{"status":"error","timestamp":1583239665299,"user_tz":-540,"elapsed":794,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["# args = parser.parse_args()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["usage: ipykernel_launcher.py [-h] [--config CONFIG]\n","ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-aa6a7091-e67a-428b-897f-21ec4597b988.json\n"],"name":"stderr"},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"L1Pd3IyHbm4n","colab_type":"code","colab":{}},"source":["# Set seeds for reproducibility\n","np.random.seed(500)\n","tf.random.set_seed(500)\n","\n","# Set global constants\n","embedding_dim = 128     # number of dimensions to represent each character in vector space\n","batch_size = 100        # feed in the neural network in 100-example training batches\n","num_epochs = 30         # number of times the neural network goes over EACH training example\n","# config = int(args.config)  # model-configuration"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wgz8UQrocMPo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"cce03ef3-9225-473a-c8a9-6ff65bf61daa","executionInfo":{"status":"ok","timestamp":1583239719742,"user_tz":-540,"elapsed":815,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["# Load Spanish-to-English dataset (.zip)\n","zipped = get_file(\n","    fname='spa-eng.zip',\n","    origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n","    extract=True)\n","\n","file = os.path.join(os.path.dirname(zipped), 'spa-eng/spa.txt')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n","2646016/2638744 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k9mnHNu3cOfY","colab_type":"code","colab":{}},"source":["def unicode_to_ascii(string):\n","    \"\"\"Function to convert the string from unicode file to ascii format\"\"\"\n","    return ''.join(char for char in unicodedata.normalize('NFD', string)\n","                   if unicodedata.category(char) != 'Mn')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hkO_n9W5cQPU","colab_type":"code","colab":{}},"source":["def preprocess_sentence(sentence):\n","    \"\"\"\n","    Function to preprocess sentences according to machine translation conventions. Includes\n","    conversion to ascii characters, general cleaning operations, and removal of accents.\n","    \"\"\"\n","    sentence = unicode_to_ascii(sentence.lower().strip())\n","    # Creates a space between a word and the punctuation following it, ex: \"hi dad.\" => \"hi dad .\"\n","    sentence = re.sub(r'([?.!,¿])', r' \\1 ', sentence)\n","    sentence = re.sub(r'[\" \"]+', ' ', sentence)\n","\n","    # Replace everything with space except (a-z, A-Z, '.', '?', '!', ',')\n","    sentence = re.sub(r'[^a-zA-Z?.!,¿]+', ' ', sentence)\n","\n","    # Remove spaces\n","    sentence = sentence.rstrip().strip()\n","\n","    # Add a start and an end token to the sentence for the model to recognize\n","    sentence = '<start> ' + sentence + ' <end>'\n","    return sentence"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l-Ok5bkIcSRs","colab_type":"code","colab":{}},"source":["def create_dataset(path, num_examples):\n","    \"\"\"Returns sentence pairs in [ENGLISH, SPANISH] format\"\"\"\n","    lines = open(path, encoding='utf8').read().strip().split('\\n')\n","    word_pairs = [[preprocess_sentence(sentence)\n","                   for sentence in line.split('\\t')]\n","                  for line in lines[:num_examples]]\n","    return zip(*word_pairs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YpxaDi9LcT3A","colab_type":"code","colab":{}},"source":["# Load and process pairwise English and Spanish sentences\n","english_sentences, spanish_sentences = create_dataset(path=file, num_examples=None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fSjNI75ycVsg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"00a148c3-4c80-408d-87b0-46004d4ac884","executionInfo":{"status":"ok","timestamp":1583239765086,"user_tz":-540,"elapsed":622,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["english_sentences[:5]"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('<start> go . <end>',\n"," '<start> go . <end>',\n"," '<start> go . <end>',\n"," '<start> go . <end>',\n"," '<start> hi . <end>')"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"jCpO-jRLcazh","colab_type":"code","colab":{}},"source":["def max_length(tensor):\n","    \"\"\"Function that returns the maximum length of any element in a given tensor\"\"\"\n","    return max(len(tensor_unit) for tensor_unit in tensor)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ej_Uy8oucbM1","colab_type":"code","colab":{}},"source":["def tokenize(language):\n","    \"\"\"Function to tokenize language by mapping words to integer indices\"\"\"\n","    # Perform tokenization\n","    language_tokenizer = Tokenizer(filters='')\n","    language_tokenizer.fit_on_texts(language)\n","    tensor = language_tokenizer.texts_to_sequences(language)\n","    # Pad sequences to maximum found sequence length by appending 0s to end\n","    tensor = pad_sequences(sequences=tensor, padding='post')\n","\n","    return tensor, language_tokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O8JWuBiyccvJ","colab_type":"code","colab":{}},"source":["def load_dataset(path, num_examples=None):\n","    \"\"\"Function to load dataset\"\"\"\n","    # Create cleaned input-output pairs\n","    target_language, input_language = create_dataset(path, num_examples)\n","    # Create language tokenizers and extract tensors\n","    input_tensor, input_language_tokenizer = tokenize(input_language)\n","    target_tensor, target_language_tokenizer = tokenize(target_language)\n","\n","    return input_tensor, target_tensor, input_language_tokenizer, target_language_tokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jm7dlFzFcegc","colab_type":"code","colab":{}},"source":["# Get example (input) tensors, label (target) tensors, and distinct tokenizers for both languages\n","input_tensor, target_tensor, input_language_tokenizer, target_language_tokenizer = load_dataset(\n","    path=file, num_examples=None\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qhWoS192ciJf","colab_type":"code","colab":{}},"source":["# Setup more global constants\n","input_vocabulary_size = len(input_language_tokenizer.word_index) + 1\n","target_vocabulary_size = len(target_language_tokenizer.word_index) + 1\n","\n","# Calculate maximum sequence lengths of the input and target tensors\n","input_sequence_length, target_sequence_length = max_length(input_tensor), max_length(target_tensor)\n","\n","# Split data to training and validation sets\n","X_train, X_test, Y_train, Y_test = train_test_split(input_tensor,\n","                                                    target_tensor,\n","                                                    test_size=0.2,\n","                                                    random_state=500)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yyCl03Ftd0i3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"d33f6442-bda5-4007-c525-c7835d62905f","executionInfo":{"status":"ok","timestamp":1583240142018,"user_tz":-540,"elapsed":639,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["input_sequence_length"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["53"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"BkS59zo6d1my","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"650e709b-7f68-4108-b825-d4b4427bc8df","executionInfo":{"status":"ok","timestamp":1583240143940,"user_tz":-540,"elapsed":625,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["target_sequence_length"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["51"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"iMMM6-hYcmH6","colab_type":"code","colab":{}},"source":["# Compute batch size and cutoff training & validation examples to fit\n","training_cutoff, test_cutoff = len(X_train) % batch_size, len(X_test) % batch_size\n","\n","X_train, Y_train = X_train[:-training_cutoff], Y_train[:-training_cutoff]\n","\n","X_test, Y_test = X_test[:-test_cutoff], Y_test[:-test_cutoff]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tq-HChfRcqgo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"ab93ba86-05af-4f64-aeff-d8ab8baeaff9","executionInfo":{"status":"ok","timestamp":1583239838524,"user_tz":-540,"elapsed":623,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["X_train.shape"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(95100, 53)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"Kr8eX5_JcxPe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"a2ac90e5-59ff-415d-b303-88abcdbd17c1","executionInfo":{"status":"ok","timestamp":1583239865425,"user_tz":-540,"elapsed":631,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["X_train[:1]"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   1,   10,  254, 3263,   36,  144,    4, 2227,    7,   10,  560,\n","           3,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0]],\n","      dtype=int32)"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"nZ28B6xRcwsk","colab_type":"code","colab":{}},"source":["# Feed in current labels (Y) as decoder inputs, and pad current labels by 1 word\n","# Check https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg for better understanding\n","X_train_target, X_test_target = Y_train, Y_test\n","\n","Y_train = np.array(pad_sequences(sequences=np.array([sequence[1:] for sequence in Y_train]),\n","                                 maxlen=target_sequence_length,\n","                                 padding='post'))\n","\n","Y_test = np.array(pad_sequences(sequences=np.array([sequence[1:] for sequence in Y_test]),\n","                                maxlen=target_sequence_length,\n","                                padding='post'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MVvOuSXrc4D0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"a69a9a82-5e57-4b90-e958-492ca7021067","executionInfo":{"status":"ok","timestamp":1583239895730,"user_tz":-540,"elapsed":647,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["Y_train[0]"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   5,  387, 1187,    5,  152,   80,   60, 1999,    5,  300,    3,\n","          2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"q6ZZckg_cwrg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"f3e807a8-ecd7-4f1c-96a8-7b1b4f969b00","executionInfo":{"status":"ok","timestamp":1583239911584,"user_tz":-540,"elapsed":615,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["X_train_target[0]"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   1,    5,  387, 1187,    5,  152,   80,   60, 1999,    5,  300,\n","          3,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"growtV7TdDO2","colab_type":"text"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"TBD8I9RPfZCR","colab_type":"code","colab":{}},"source":["class Attention(tf.keras.layers.Layer):\n","  def __init__(self, **kwargs):\n","    super(Attention, self).__init__(**kwargs)\n","\n","  def build(self, input_shape):\n","    # input should be (B, t, h)\n","    self.input_sequence_length = input_shape[0][1]  # number of input sequence length  \n","                                                    # input((10,)) -> embedding(100, 128) == None, 10, 128\n","    self.hidden_dim = input_shape[0][2]             # last layer units\n","    self.target_sequence_length = input_shape[1][1] # the model inputs : model.fit([x1, x2])\n","\n","    self.W_a = Dense(units=self.hidden_dim, use_bias=False)\n","    self.W_a.build(input_shape=(None, None, self.hidden_dim))\n","    self._trainable_weights += self.W_a._trainable_weights\n","\n","    super(Attention, self).build(input_shape)\n","  \n","  def call(self, inputs): # input should be\n","    target_hidden_state = inputs[1]\n","    # print('target_hidden_state', target_hidden_state)\n","    current_timestep = inputs[2]\n","    # print('current_timestep', current_timestep)\n","    source_hidden_states = inputs[0]\n","    # print('source_hidden_states', source_hidden_states)  # from decoder\n","\n","    target_hidden_state = tf.expand_dims(target_hidden_state, 1)\n","    # print('target_hidden_state_expand_dim', target_hidden_state)\n","\n","    #Global\n","    source_hidden_states = source_hidden_states\n","\n","    # General\n","    weighted_hidden_states = self.W_a(source_hidden_states)\n","    attention_score = tf.keras.layers.Dot(axes=[2,2])([weighted_hidden_states, target_hidden_state])\n","\n","    attention_weights = tf.keras.layers.Activation('softmax')(attention_score)\n","\n","    context_vector = source_hidden_states * attention_score\n","    return context_vector, attention_weights\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wMXe3jnPf22Y","colab_type":"code","colab":{}},"source":["test_input = Input(shape=(10,))\n","x = Embedding(100, 128)(test_input)\n","x = CuDNNLSTM(128, return_sequences=True)(x)  # encoder ouput \n","\n","d_input = Input(shape=(10,))\n","d_e = Embedding(100, 128)(d_input)\n","\n","decoder_lstm = CuDNNLSTM(128, return_state=True)\n","d, d_h_s, d_h_c = decoder_lstm(d_e)\n","\n","decoder_dense_layer = Dense(units=10, activation='softmax')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iy51bXTmnGwb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"e04fd97e-8600-43d8-c5f1-52d684cc7002","executionInfo":{"status":"ok","timestamp":1583242573873,"user_tz":-540,"elapsed":847,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["d_e"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'embedding_16/Identity:0' shape=(None, 10, 128) dtype=float32>"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"27EywNtdle4q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"fd6d66a1-fdff-44bc-f0a1-32aeed7ae61c","executionInfo":{"status":"ok","timestamp":1583242213703,"user_tz":-540,"elapsed":642,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["print(x) # return sequence\n","print(d) # \n","print(d_h_s)\n","print(d_c_s)"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Tensor(\"cu_dnnlstm_8/Identity:0\", shape=(None, 10, 128), dtype=float32)\n","Tensor(\"cu_dnnlstm_9/Identity:0\", shape=(None, 128), dtype=float32)\n","Tensor(\"cu_dnnlstm_9/Identity_1:0\", shape=(None, 128), dtype=float32)\n","Tensor(\"cu_dnnlstm_9/Identity_2:0\", shape=(None, 128), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pm32loJwf88_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"fe24108e-21a1-4d9d-98b3-2543bb7c44ca","executionInfo":{"status":"ok","timestamp":1583242392234,"user_tz":-540,"elapsed":618,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["x = Attention()([x, d_h_s, 0]) # only one time step"],"execution_count":59,"outputs":[{"output_type":"stream","text":["target_hidden_state Tensor(\"cu_dnnlstm_13/Identity_1:0\", shape=(None, 128), dtype=float32)\n","current_timestep tf.Tensor(0, shape=(), dtype=int32)\n","source_hidden_states Tensor(\"cu_dnnlstm_12/Identity:0\", shape=(None, 10, 128), dtype=float32)\n","target_hidden_state_expand_dim Tensor(\"ExpandDims_2:0\", shape=(None, 1, 128), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B5oyTglVnRBz","colab_type":"code","colab":{}},"source":["tf.keras.backend.clear_session()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9uy9Uxh_mWjx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"outputId":"d971a6a4-64dc-4d1d-f864-d4bdc0e5388e","executionInfo":{"status":"ok","timestamp":1583243123312,"user_tz":-540,"elapsed":1720,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["attention_layer = Attention()\n","\n","outputs = []\n","for timestep in range(10):\n","  current_word = tf.keras.layers.Lambda(lambda x: x[:, timestep:timestep+1, :])(d_e) #0:1, 1:2, \n","  # print(current_word)\n","  context_vector, attention_weights = attention_layer([x, d_h_s, timestep])\n","  # print(context_vector)\n","\n","  decoder_input = Concatenate(axis=1)([context_vector, current_word])\n","  print(decoder_input)\n","\n","  d, d_h_s, d_h_c = decoder_lstm(decoder_input, initial_state=[d_h_s, d_h_c])\n","\n","  decoder_output = decoder_dense_layer(d)\n","  outputs.append(decoder_output)"],"execution_count":92,"outputs":[{"output_type":"stream","text":["Tensor(\"concatenate_24/Identity:0\", shape=(None, 11, 128), dtype=float32)\n","Tensor(\"concatenate_25/Identity:0\", shape=(None, 11, 128), dtype=float32)\n","Tensor(\"concatenate_26/Identity:0\", shape=(None, 11, 128), dtype=float32)\n","Tensor(\"concatenate_27/Identity:0\", shape=(None, 11, 128), dtype=float32)\n","Tensor(\"concatenate_28/Identity:0\", shape=(None, 11, 128), dtype=float32)\n","Tensor(\"concatenate_29/Identity:0\", shape=(None, 11, 128), dtype=float32)\n","Tensor(\"concatenate_30/Identity:0\", shape=(None, 11, 128), dtype=float32)\n","Tensor(\"concatenate_31/Identity:0\", shape=(None, 11, 128), dtype=float32)\n","Tensor(\"concatenate_32/Identity:0\", shape=(None, 11, 128), dtype=float32)\n","Tensor(\"concatenate_33/Identity:0\", shape=(None, 11, 128), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"98Qmn0u5muOW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"outputId":"6035d94d-98ba-4d68-d2bd-e50ca932586b","executionInfo":{"status":"ok","timestamp":1583243126583,"user_tz":-540,"elapsed":583,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["outputs"],"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Tensor 'dense_10/Identity:0' shape=(None, 10) dtype=float32>,\n"," <tf.Tensor 'dense_10_1/Identity:0' shape=(None, 10) dtype=float32>,\n"," <tf.Tensor 'dense_10_2/Identity:0' shape=(None, 10) dtype=float32>,\n"," <tf.Tensor 'dense_10_3/Identity:0' shape=(None, 10) dtype=float32>,\n"," <tf.Tensor 'dense_10_4/Identity:0' shape=(None, 10) dtype=float32>,\n"," <tf.Tensor 'dense_10_5/Identity:0' shape=(None, 10) dtype=float32>,\n"," <tf.Tensor 'dense_10_6/Identity:0' shape=(None, 10) dtype=float32>,\n"," <tf.Tensor 'dense_10_7/Identity:0' shape=(None, 10) dtype=float32>,\n"," <tf.Tensor 'dense_10_8/Identity:0' shape=(None, 10) dtype=float32>,\n"," <tf.Tensor 'dense_10_9/Identity:0' shape=(None, 10) dtype=float32>]"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"code","metadata":{"id":"LvCm6084pZsv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"4a6e615f-78d2-423c-ab66-180ec9ddb46c","executionInfo":{"status":"ok","timestamp":1583243177423,"user_tz":-540,"elapsed":606,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["tf.stack(outputs)"],"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'stack:0' shape=(10, None, 10) dtype=float32>"]},"metadata":{"tags":[]},"execution_count":94}]},{"cell_type":"code","metadata":{"id":"QMW6zFYmpPYF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"cb3da4ef-d580-4361-b62a-3b7c90e047de","executionInfo":{"status":"ok","timestamp":1583243200566,"user_tz":-540,"elapsed":586,"user":{"displayName":"Seunghwan Oh","photoUrl":"","userId":"13780782377671471234"}}},"source":["outputs = tf.keras.layers.Lambda(lambda x: tf.keras.backend.permute_dimensions(tf.stack(x), pattern=(1,0,2)))(outputs)\n","\n","outputs"],"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'lambda_75/Identity:0' shape=(None, 10, 10) dtype=float32>"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"code","metadata":{"id":"zx9hVyiadDuU","colab_type":"code","colab":{}},"source":["# Create word-level multi-class classification (machine translation), sequence-to-sequence model\n","# Input Layers\n","# i)  Initialize input & target sequences\n","X_input = Input(shape=(input_sequence_length,), batch_size=batch_size, name='input_sequences')\n","X_target = Input(shape=(target_sequence_length,), batch_size=batch_size, name='target_sequences')\n","\n","\n","# ii) Initialize hidden & cell states\n","initial_hidden_state = Input(shape=(128,), batch_size=batch_size, name='hidden_state')\n","initial_cell_state = Input(shape=(128,), batch_size=batch_size, name='cell_state')\n","\n","hidden_state, cell_state = initial_hidden_state, initial_cell_state\n","# NOTE: Here hidden state refers to the recurrently propagated input to the cell, whereas cell\n","# state refer to the cell state directly from the previous cell."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"unC39DhQdLOa","colab_type":"code","colab":{}},"source":["# Word-Embedding Layers\n","# i)  Embed input sequences from the input language\n","embedded_input = Embedding(input_dim=input_vocabulary_size, output_dim=embedding_dim)(X_input)\n","# ii) Embed target sequences from the target language\n","embedded_target = Embedding(input_dim=target_vocabulary_size, output_dim=embedding_dim)(X_target)\n","# NOTE: The embedded target sequences (deriving from X_target) allow us to enforce Teacher Forcing:\n","# using the actual output (correct translation) from the training dataset at the current time step\n","# as input in the next time step, rather than the output generated by the network."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2C5IP51JdLgB","colab_type":"code","colab":{}},"source":["# Recurrent Layers\n","# i)  Encoder\n","encoder_output = CuDNNLSTM(units=128, return_sequences=True)(embedded_input)\n","\n","# ii) Decoder\n","decoder_recurrent_layer = CuDNNLSTM(units=128, return_state=True)\n","# NOTE: The encoder is always fully vectorized and returns the hidden representations of the whole\n","# sequence at once, whereas the decoder does this step by step.\n"],"execution_count":0,"outputs":[]}]}