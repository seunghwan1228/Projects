{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport os\nfrom keras import models, layers\nfrom keras.preprocessing import image\nfrom sklearn.model_selection import train_test_split\nfrom keras.applications import Xception\nfrom keras import optimizers, callbacks\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('../input/aptos2019-blindness-detection/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create img path\nimg_path_impute = lambda x : x + '.png'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_path_impute(train_df.loc[0, 'id_code'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['img_path'] = train_df.loc[:, 'id_code'].apply(img_path_impute)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot('diagnosis', data = train_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# img_path = f'train_images/{train_df['id_code']}'\n\nimg_test = plt.imread('test_images/270a532df702.png')\nplt.imshow(img_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split train test\nx = train_df['img_path']\ny = train_df['diagnosis']\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=1228, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full = pd.concat([X_train, y_train], axis=1)\ntest_full = pd.concat([X_test, y_test], axis=1)\n\ntrain_full['diagnosis'] = train_full['diagnosis'].astype('str')\ntest_full['diagnosis'] = test_full['diagnosis'].astype('str')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checker \ntrain_df[train_df.index == 2225]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = image.ImageDataGenerator(rescale = 1./255,\n                                     rotation_range=0.2,\n                                     shear_range=0.2,\n                                     horizontal_flip=True,\n                                     vertical_flip=True,\n                                     width_shift_range=0.2,\n                                     height_shift_range = 0.2)\n\ntest_gen = image.ImageDataGenerator(rescale = 1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir('train_images'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_dir = 'train_images/'\ntrain_data = train_gen.flow_from_dataframe(train_full, directory = img_dir, x_col = 'img_path', y_col = 'diagnosis', target_size=(299, 299), class_mode='categorical', batch_size=32)\n\ntest_data = test_gen.flow_from_dataframe(test_full, directory = img_dir, x_col = 'img_path', y_col = 'diagnosis', target_size=(299,299), class_mode='categorical', batch_size=32)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_step = train_data.n // train_data.batch_size\ntest_step = test_data.n // test_data.batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counter = 0\nfor batch in train_data:\n    img_batch = batch[0]\n    for img in range(img_batch.shape[0]):\n        plt.figure()\n        plt.imshow(img_batch[img])\n        \n    counter += 1\n    if counter == 1:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xception = Xception(include_top =False, input_shape=(299,299,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(xception)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dense(5, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_opt = optimizers.nadam(lr=0.01)\ncall_early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=3)\ncall_reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, min_lr = 1e-9, verbose=1)\ncall_model_save = callbacks.ModelCheckpoint(filepath = 'test_model.h5', save_best_only=True, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer=my_opt, metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_v1 = model.fit_generator(train_data, \n                    steps_per_epoch=train_step, \n                    epochs=100, \n                    validation_data=test_data,\n                    validation_steps=test_step, \n                    callbacks=[call_reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(xception)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dense(1024, activation='relu'))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(5, activation='softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer=my_opt, metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_v1 = model.fit_generator(train_data, \n                    steps_per_epoch=train_step, \n                    epochs=100, \n                    validation_data=test_data,\n                    validation_steps=test_step, \n                    callbacks=[call_reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display image from kernel : densenet-keras-starter\ndef display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(5*columns, 4*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'id_code']\n        image_id = df.loc[i,'diagnosis']\n        img = cv2.imread(f'../input/aptos2019-blindness-detection/train_images/{image_path}.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        fig.add_subplot(rows, columns, i+1)\n        plt.title(image_id)\n        plt.imshow(img)\n    \n    plt.tight_layout()\n\ndisplay_samples(train_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}